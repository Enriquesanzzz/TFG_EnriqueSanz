{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42377eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphics\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Preprocessing and modelling\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import set_config\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "#warnings.filterwarnings('once')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39514a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>aid</th>\n",
       "      <th>extension</th>\n",
       "      <th>format</th>\n",
       "      <th>duration</th>\n",
       "      <th>FILE_STORED</th>\n",
       "      <th>FACIAL_ANALYSED</th>\n",
       "      <th>VOICE_ANALYSED</th>\n",
       "      <th>VOICE_TRANSCRIBED</th>\n",
       "      <th>BIOMETRICS_EXTRACTED</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>surprised_voice</th>\n",
       "      <th>no_speech_prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>tense_past</th>\n",
       "      <th>tense_present</th>\n",
       "      <th>tense_future</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1744824974</td>\n",
       "      <td>63612104-cc5c-4d54-b136-1f5880dece96</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>4.4125</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>TDAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744825004</td>\n",
       "      <td>1afe2c00-8488-40f2-b3e1-5bd90fd57ad8</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>video</td>\n",
       "      <td>213.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0.372388</td>\n",
       "      <td>4.3565</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>TDAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744825017</td>\n",
       "      <td>6c987224-499c-469a-b908-dffef38c48b4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>video</td>\n",
       "      <td>115.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.190980</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>4.1783</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744825025</td>\n",
       "      <td>e34d8573-7371-486a-900c-32a6ee78fabe</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>video</td>\n",
       "      <td>202.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.102629</td>\n",
       "      <td>4.2469</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744825037</td>\n",
       "      <td>5b442dc9-a39a-47e2-ba05-b0fe880ee44b</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>video</td>\n",
       "      <td>135.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.047226</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>4.2440</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at                                   aid extension format  \\\n",
       "0  1744824974  63612104-cc5c-4d54-b136-1f5880dece96      .mp4  video   \n",
       "1  1744825004  1afe2c00-8488-40f2-b3e1-5bd90fd57ad8      .mp4  video   \n",
       "2  1744825017  6c987224-499c-469a-b908-dffef38c48b4      .mp4  video   \n",
       "3  1744825025  e34d8573-7371-486a-900c-32a6ee78fabe      .mp4  video   \n",
       "4  1744825037  5b442dc9-a39a-47e2-ba05-b0fe880ee44b      .mp4  video   \n",
       "\n",
       "   duration  FILE_STORED  FACIAL_ANALYSED  VOICE_ANALYSED  VOICE_TRANSCRIBED  \\\n",
       "0       NaN         True             True           False               True   \n",
       "1     213.0         True             True            True               True   \n",
       "2     115.0         True             True            True               True   \n",
       "3     202.0         True             True            True               True   \n",
       "4     135.0         True             True            True               True   \n",
       "\n",
       "   BIOMETRICS_EXTRACTED  ...  language  surprised_voice no_speech_prob  \\\n",
       "0                 False  ...        en              NaN       0.006900   \n",
       "1                  True  ...        en         0.043251       0.372388   \n",
       "2                  True  ...        es         0.190980       0.086458   \n",
       "3                  True  ...        es         0.006369       0.102629   \n",
       "4                  True  ...        es         0.047226       0.055492   \n",
       "\n",
       "   entropy  tense_past  tense_present  tense_future  sentiment_polarity  \\\n",
       "0   4.4125      0.3158         0.6842        0.0000              0.0932   \n",
       "1   4.3565      0.0769         0.9231        0.0000              0.2364   \n",
       "2   4.1783      0.0000         1.0000        0.0000              0.3056   \n",
       "3   4.2469      0.0833         0.7500        0.1667              0.2268   \n",
       "4   4.2440      0.0833         0.9167        0.0000              0.2170   \n",
       "\n",
       "   sentiment_subjectivity  variable  \n",
       "0                  0.5386      TDAH  \n",
       "1                  0.5069      TDAH  \n",
       "2                  0.5162   Autismo  \n",
       "3                  0.5349   Autismo  \n",
       "4                  0.5825   Autismo  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('CSV_DEF_CLASIF.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1839a178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas tras la limpieza: 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry_facial</th>\n",
       "      <th>disgust_facial</th>\n",
       "      <th>fear_facial</th>\n",
       "      <th>happy_facial</th>\n",
       "      <th>sad_facial</th>\n",
       "      <th>surprise_facial</th>\n",
       "      <th>neutral_facial</th>\n",
       "      <th>most_frequent_dominant_emotion</th>\n",
       "      <th>dominant_emotion_counts_surprise</th>\n",
       "      <th>average_face_confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>surprised_voice</th>\n",
       "      <th>no_speech_prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>tense_past</th>\n",
       "      <th>tense_present</th>\n",
       "      <th>tense_future</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>4.4125</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>TDAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0.372388</td>\n",
       "      <td>4.3565</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>TDAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.190980</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>4.1783</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.3593</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.2969</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.102629</td>\n",
       "      <td>4.2469</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>...</td>\n",
       "      <td>es</td>\n",
       "      <td>0.047226</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>4.2440</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>Autismo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   angry_facial  disgust_facial  fear_facial  happy_facial  sad_facial  \\\n",
       "0        0.2098          0.0008       0.4117        0.1561      0.2053   \n",
       "1        0.0271          0.0000       0.1126        0.0005      0.6216   \n",
       "2        0.1140          0.0000       0.1678        0.0062      0.4205   \n",
       "3        0.0931          0.0771       0.1322        0.0408      0.3593   \n",
       "4        0.0315          0.0001       0.0204        0.4411      0.2166   \n",
       "\n",
       "   surprise_facial  neutral_facial most_frequent_dominant_emotion  \\\n",
       "0           0.0063          0.0099                            sad   \n",
       "1           0.0001          0.2381                            sad   \n",
       "2           0.0020          0.2895                            sad   \n",
       "3           0.0007          0.2969                            sad   \n",
       "4           0.0009          0.2895                        neutral   \n",
       "\n",
       "   dominant_emotion_counts_surprise  average_face_confidence  ...  language  \\\n",
       "0                               NaN                   0.9500  ...        en   \n",
       "1                               NaN                   0.9200  ...        en   \n",
       "2                               NaN                   0.9833  ...        es   \n",
       "3                               NaN                   0.9500  ...        es   \n",
       "4                               NaN                   0.9167  ...        es   \n",
       "\n",
       "   surprised_voice  no_speech_prob  entropy  tense_past  tense_present  \\\n",
       "0              NaN        0.006900   4.4125      0.3158         0.6842   \n",
       "1         0.043251        0.372388   4.3565      0.0769         0.9231   \n",
       "2         0.190980        0.086458   4.1783      0.0000         1.0000   \n",
       "3         0.006369        0.102629   4.2469      0.0833         0.7500   \n",
       "4         0.047226        0.055492   4.2440      0.0833         0.9167   \n",
       "\n",
       "   tense_future  sentiment_polarity  sentiment_subjectivity  variable  \n",
       "0        0.0000              0.0932                  0.5386      TDAH  \n",
       "1        0.0000              0.2364                  0.5069      TDAH  \n",
       "2        0.0000              0.3056                  0.5162   Autismo  \n",
       "3        0.1667              0.2268                  0.5349   Autismo  \n",
       "4        0.0000              0.2170                  0.5825   Autismo  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copia del dataframe original\n",
    "df = data.copy()\n",
    "\n",
    "# Columnas a eliminar (sin eliminar 'language')\n",
    "cols_to_drop = [\n",
    "    'created_at', 'aid', 'extension', 'format', 'duration',\n",
    "    'FILE_STORED', 'FACIAL_ANALYSED', 'VOICE_ANALYSED', 'VOICE_TRANSCRIBED',\n",
    "    'BIOMETRICS_EXTRACTED', 'SPEECH_ANALYSED', 'PERSONALITY_ANALYSED',\n",
    "    'FACES_EXTRACTED', 'id'\n",
    "]\n",
    "\n",
    "# Eliminar columnas\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Comprobación\n",
    "print(f\"Número de columnas tras la limpieza: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6c06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases tras eliminar Dispraxia:\n",
      "variable\n",
      "Autismo     2093\n",
      "Control     2033\n",
      "TDAH        2030\n",
      "Dislexia    2026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con clase 'Dispraxia'\n",
    "df = df[df['variable'] != 'Dispraxia'].copy()\n",
    "\n",
    "# Comprobación\n",
    "print(\"Distribución de clases tras eliminar Dispraxia:\")\n",
    "print(df['variable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b970967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dominant_emotion_counts_surprise    7184\n",
       "neutral_facial                       988\n",
       "disgust_facial                       988\n",
       "average_face_confidence              988\n",
       "most_frequent_dominant_emotion       988\n",
       "angry_facial                         988\n",
       "surprise_facial                      988\n",
       "sad_facial                           988\n",
       "happy_facial                         988\n",
       "fear_facial                          988\n",
       "voice_kurtosis                       351\n",
       "voice_median                         351\n",
       "voice_mode                           351\n",
       "voice_Q25                            351\n",
       "voice_Q75                            351\n",
       "voice_IQR                            351\n",
       "voice_skewness                       351\n",
       "voice_Q75_note                       351\n",
       "voice_mean_note                      351\n",
       "voice_median_note                    351\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver número de valores nulos por columna (ordenado)\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b3b3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset: (8182, 68)\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamaño del dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46579b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columna con demasiados nulos\n",
    "df.drop(columns=['dominant_emotion_counts_surprise'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24d99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Columna categórica 'most_frequent_dominant_emotion' rellenada con su moda\n",
      "ℹ️ Columna categórica 'voice_mean_note' rellenada con su moda\n",
      "ℹ️ Columna categórica 'voice_median_note' rellenada con su moda\n",
      "ℹ️ Columna categórica 'voice_mode_note' rellenada con su moda\n",
      "ℹ️ Columna categórica 'voice_Q25_note' rellenada con su moda\n",
      "ℹ️ Columna categórica 'voice_Q75_note' rellenada con su moda\n",
      "ℹ️ Columna categórica 'language' rellenada con su moda\n",
      "\n",
      "✅ Nulos restantes tras limpieza: 0\n"
     ]
    }
   ],
   "source": [
    "columnas_con_nulos = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# 3. Rellenar según el tipo de dato\n",
    "for col in columnas_con_nulos:\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        print(f\"ℹ️ Columna categórica '{col}' rellenada con su moda\")\n",
    "\n",
    "# 4. Comprobar que ya no quedan nulos\n",
    "total_nulos = df.isnull().sum().sum()\n",
    "print(f\"\\n✅ Nulos restantes tras limpieza: {total_nulos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f318ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset después (para comprobar que no se eliminan filas): (8182, 67)\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamaño del dataset después (para comprobar que no se eliminan filas):\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f30c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas a codificar: ['most_frequent_dominant_emotion', 'voice_mean_note', 'voice_median_note', 'voice_mode_note', 'voice_Q25_note', 'voice_Q75_note', 'language']\n",
      "Tamaño X_train: (6545, 179)\n",
      "Tamaño X_test: (1637, 179)\n",
      "Distribución de clases en y_train:\n",
      " variable\n",
      "Autismo     1674\n",
      "Control     1626\n",
      "TDAH        1624\n",
      "Dislexia    1621\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Separar X e y\n",
    "X = df.drop(columns=['variable'])  # variable objetivo\n",
    "y = df['variable']\n",
    "\n",
    "# 2. Identificar columnas categóricas para codificar\n",
    "columnas_categoricas = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(\"Columnas categóricas a codificar:\", columnas_categoricas)\n",
    "\n",
    "# 3. Aplicar OneHotEncoding\n",
    "X = pd.get_dummies(X, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# 4. Dividir en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Comprobación final\n",
    "print(\"Tamaño X_train:\", X_train.shape)\n",
    "print(\"Tamaño X_test:\", X_test.shape)\n",
    "print(\"Distribución de clases en y_train:\\n\", y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afee382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1c4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
